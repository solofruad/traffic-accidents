{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Train & Test) Doc2vec\n",
    "### By **N√©stor Suat** in 2019\n",
    "\n",
    "**Descripci√≥n:** Entrenando y probando los modelos doc2vec (entrenados previamente) con SVM. \n",
    "\n",
    "**Input:**\n",
    "* Train and Test set\n",
    "* Doc2vec model (DBOW or DMM or both of them)\n",
    "\n",
    "**Output:**\n",
    "* Metrics: confusion matrix, accuracy, recall, precision and F1-score\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Cargando datos y limpieza\n",
    "\n",
    "### Importando librer√≠as\n",
    "\n",
    "Como estamos en un archivo afuera se necesita agregar la direcci√≥n ../ (ra√≠z del proyexto) para importar la librer√≠a de preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from classes.doc2vec.preprocessing import Preprocessing as doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.17.3\n",
      "gensim 3.8.1\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(\"numpy\",numpy.version.version)\n",
    "\n",
    "import gensim\n",
    "print(\"gensim\", gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3804, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üì¢#Atenci√≥n: se presenta siniestro vial entre u...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üì¢#Atenci√≥n: a esta hora se presentan disturbio...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Incidente vial entre taxi üöñ y‚Äç motocicleta üèçÔ∏è ...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chemabernal @Moniva0517 @MartinSantosR La gr√°...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @CaracolRadio: #CaracolEsM√°s | ¬°Atenci√≥n! F...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  dataset\n",
       "0  üì¢#Atenci√≥n: se presenta siniestro vial entre u...      1       99\n",
       "1  üì¢#Atenci√≥n: a esta hora se presentan disturbio...      0       99\n",
       "2  Incidente vial entre taxi üöñ y‚Äç motocicleta üèçÔ∏è ...      1       99\n",
       "3  @chemabernal @Moniva0517 @MartinSantosR La gr√°...      0       99\n",
       "4  RT @CaracolRadio: #CaracolEsM√°s | ¬°Atenci√≥n! F...      1       99"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../../../data/v1/7030/train70.tsv\", delimiter = \"\\t\", quoting = 3)\n",
    "train['dataset'] = 99 # train = 1\n",
    "test = pd.read_csv(\"../../../data/v1/7030/test30.tsv\", delimiter = \"\\t\", quoting = 3)\n",
    "test['dataset'] = 100 # test = 0\n",
    "dataset = pd.concat([train,test])\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "print(dataset.shape) # (3804, 3)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1_clean_stem_stopwords_dataset_propuesta1_5050\n",
    "1_clean_stem_stopwords_dataset_propuesta2_complete\n",
    "2_clean_lemma_stopwords_dataset_propuesta1_5050\n",
    "2_clean_lemma_stopwords_dataset_propuesta2_complete\n",
    "**3_clean_stopwords_dataset_propuesta1_5050\n",
    "**3_clean_stopwords_dataset_propuesta2_complete\n",
    "4_clean_special_chars_dataset_propuesta1_5050\n",
    "4_clean_special_chars_dataset_propuesta2_complete\n",
    "5_clean_stem_dataset_propuesta1_5050\n",
    "5_clean_stem_dataset_propuesta2_complete\n",
    "6_clean_lemma_dataset_propuesta1_5050\n",
    "6_clean_lemma_dataset_propuesta2_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#directory = \"../../../data/v1/doc2vec/\"\n",
    "#directory = \"../../../data/v1/doc2vec/v2/\"\n",
    "#directory = \"../../../data/v1/doc2vec/v3/\"\n",
    "#directory = \"../../../data/v1/doc2vec/v4/\"\n",
    "directory = \"../../../data/v1/doc2vec/v5/\"\n",
    "\n",
    "file = \"6_clean_lemma_dataset_propuesta1_5050\"\n",
    "#file = \"test30\"\n",
    "type_clean = 6 #Tiene que ser el mismo que 'file' (prefijo)\n",
    "\n",
    "#Model SVM\n",
    "kernel='rbf'\n",
    "gamma=0.2\n",
    "C=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = doc2vec(dataset)\n",
    "clean.fit_clean(type_clean)\n",
    "\n",
    "embendding = clean.feature_extraction_dbow100(directory, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test set\n",
    "Para el preprocesamiento uno los conjuntos, aqu√≠ vuelvo a separarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.format_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_train = embendding[embendding[:,0] == 99.0,:] #train = 99\n",
    "vecs_test = embendding[embendding[:,0] == 100.0,:] #test = 100\n",
    "\n",
    "X_train = vecs_train[:,2:]\n",
    "y_train = vecs_train[:,1]\n",
    "X_test = vecs_test[:,2:]\n",
    "y_test = vecs_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embendding[:,2:]\n",
    "y = embendding[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size vecs_train (2662, 102)\n",
      "Size vecs_test (1142, 102)\n",
      "Size: \n",
      " * X_train: (2662, 100) \n",
      " * y_train: (2662,) \n",
      " * X_test: (1142, 100) \n",
      " * y_test: (1142,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size vecs_train\", vecs_train.shape)\n",
    "print(\"Size vecs_test\", vecs_test.shape)\n",
    "print(\"Size: \\n * X_train: %s \\n * y_train: %s \\n * X_test: %s \\n * y_test: %s\" % (X_train.shape, y_train.shape, X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (**SVM**) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(random_state=123, kernel=kernel, gamma=gamma, C=C)\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (**NB**) Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier = GaussianNB()\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (**RF**) Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_estimators = 1000\n",
    "min_samples_split = 5\n",
    "min_samples_leaf = 1\n",
    "max_features = 'sqrt'\n",
    "max_depth = 100\n",
    "bootstrap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100,random_state=100,n_jobs=-1)\n",
    "\"\"\"classifier = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                    min_samples_split=min_samples_split,\n",
    "                                    min_samples_leaf=min_samples_leaf,\n",
    "                                    max_features=max_features,\n",
    "                                    max_depth=max_depth,\n",
    "                                    bootstrap=bootstrap,\n",
    "                                    random_state=100,n_jobs=-1)\n",
    "\"\"\"\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation solo con datos de entrenamiento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "skfold = StratifiedKFold(n_splits=10, random_state=100)\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold)\n",
    "print(\"Accuracy: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold, scoring='f1_macro')\n",
    "print(\"F1-score: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold, scoring='recall_macro')\n",
    "print(\"Recall: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold, scoring='precision_macro')\n",
    "print(\"Precision: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation solo **todos los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958993 (+/- 0.02)\n",
      "F1-score: 0.958989 (+/- 0.02)\n",
      "Recall: 0.958993 (+/- 0.02)\n",
      "Precision: 0.959146 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=10, random_state=100)\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X, y, cv=skfold)\n",
    "print(\"Accuracy: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X, y, cv=skfold, scoring='f1_macro')\n",
    "print(\"F1-score: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X, y, cv=skfold, scoring='recall_macro')\n",
    "print(\"Recall: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X, y, cv=skfold, scoring='precision_macro')\n",
    "print(\"Precision: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "metrics_svm = []\n",
    "metrics = {}\n",
    "metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "metrics['recall'] = recall_score(y_test, y_pred)\n",
    "metrics['precision'] = precision_score(y_test, y_pred)\n",
    "metrics['f1'] = f1_score(y_test, y_pred)\n",
    "metrics_svm.append(metrics)\n",
    "metrics_svm = pd.DataFrame(metrics_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy    recall  precision        f1\n",
      "0  0.957968  0.950178   0.963899  0.956989\n",
      "[[560  20]\n",
      " [ 28 534]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics_svm)\n",
    "print(cm_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset para filtrar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "name_output = \"4_server_follow_timeline_user_M1.tsv\"\n",
    "df = pd.read_csv(\"../../../data/database/server_follow_timeline_user.tsv\", delimiter = \"\\t\", quoting = 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['dataset'] = 100 # test = 0\n",
    "df['label'] = -1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(df.shape)\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clean_df = doc2vec(df)\n",
    "clean_df.fit_clean(type_clean)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clean_df.dataset.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "end = time.perf_counter()\n",
    "print(\"Timepo de limpieza\")\n",
    "print(end - start)\n",
    "start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embendding_df = clean_df.feature_extraction_dbow(directory, file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "end = time.perf_counter()\n",
    "print(\"Timepo de embedding\")\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tweet2vec = embendding_df[embendding_df[:,0] == 100.0,:] #test = 100\n",
    "\n",
    "X_text = tweet2vec[:,2:]\n",
    "y_text = tweet2vec[:,1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_text.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "predict = classifier.predict(X_text)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(\"Timepo de predicci√≥n\")\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['label'] =  predict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "positive = df[df['label']==1.0]\n",
    "negative = df[df['label']==0.0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(positive.shape)\n",
    "print(negative.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "positive.to_csv(\"../../../data/database/output_ml/accident_\"+name_output,sep='\\t')\n",
    "negative.to_csv(\"../../../data/database/output_ml/no_accident_\"+name_output,sep='\\t')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "name_output = \"1_server_bogota_v2.tsv\"\n",
    "df.to_csv(\"../../../data/database/output_ml/accident_\"+name_output,sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
