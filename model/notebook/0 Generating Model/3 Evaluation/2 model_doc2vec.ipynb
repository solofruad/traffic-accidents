{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Train & Test) Doc2vec\n",
    "### By **N√©stor Suat** in 2019\n",
    "\n",
    "**Descripci√≥n:** Entrenando y probando los modelos doc2vec (entrenados previamente) con SVM. \n",
    "\n",
    "**Input:**\n",
    "* Train and Test set\n",
    "* Doc2vec model (DBOW or DMM or both of them)\n",
    "\n",
    "**Output:**\n",
    "* Metrics: confusion matrix, accuracy, recall, precision and F1-score\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Cargando datos y limpieza\n",
    "\n",
    "### Importando librer√≠as\n",
    "\n",
    "Como estamos en un archivo afuera se necesita agregar la direcci√≥n ../ (ra√≠z del proyexto) para importar la librer√≠a de preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from classes.doc2vec.preprocessing import Preprocessing as doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3804, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üì¢#Atenci√≥n: se presenta siniestro vial entre u...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üì¢#Atenci√≥n: a esta hora se presentan disturbio...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Incidente vial entre taxi üöñ y‚Äç motocicleta üèçÔ∏è ...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@chemabernal @Moniva0517 @MartinSantosR La gr√°...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @CaracolRadio: #CaracolEsM√°s | ¬°Atenci√≥n! F...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  dataset\n",
       "0  üì¢#Atenci√≥n: se presenta siniestro vial entre u...      1       99\n",
       "1  üì¢#Atenci√≥n: a esta hora se presentan disturbio...      0       99\n",
       "2  Incidente vial entre taxi üöñ y‚Äç motocicleta üèçÔ∏è ...      1       99\n",
       "3  @chemabernal @Moniva0517 @MartinSantosR La gr√°...      0       99\n",
       "4  RT @CaracolRadio: #CaracolEsM√°s | ¬°Atenci√≥n! F...      1       99"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../../../data/v1/7030/train70.tsv\", delimiter = \"\\t\", quoting = 3)\n",
    "train['dataset'] = 99 # train = 1\n",
    "test = pd.read_csv(\"../../../data/v1/7030/test30.tsv\", delimiter = \"\\t\", quoting = 3)\n",
    "test['dataset'] = 100 # test = 0\n",
    "dataset = pd.concat([train,test])\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "print(dataset.shape) # (3804, 3)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1_clean_stem_stopwords_dataset_propuesta1_5050\n",
    "1_clean_stem_stopwords_dataset_propuesta2_complete\n",
    "2_clean_lemma_stopwords_dataset_propuesta1_5050\n",
    "2_clean_lemma_stopwords_dataset_propuesta2_complete\n",
    "**3_clean_stopwords_dataset_propuesta1_5050\n",
    "**3_clean_stopwords_dataset_propuesta2_complete\n",
    "4_clean_special_chars_dataset_propuesta1_5050\n",
    "4_clean_special_chars_dataset_propuesta2_complete\n",
    "5_clean_stem_dataset_propuesta1_5050\n",
    "5_clean_stem_dataset_propuesta2_complete\n",
    "6_clean_lemma_dataset_propuesta1_5050\n",
    "6_clean_lemma_dataset_propuesta2_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#directory = \"../../../data/v1/doc2vec/\"\n",
    "directory = \"../../../data/v1/doc2vec/v2/\"\n",
    "file = \"5_clean_stem_dataset_propuesta1_5050\"\n",
    "type_clean = 5 #Tiene que ser el mismo que 'file' (prefijo)\n",
    "\n",
    "#Model SVM\n",
    "kernel='rbf'\n",
    "gamma=0.1\n",
    "C=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = doc2vec(dataset)\n",
    "clean.fit_clean(type_clean)\n",
    "\n",
    "embendding = clean.feature_extraction_dbow(directory, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test set\n",
    "Para el preprocesamiento uno los conjuntos, aqu√≠ vuelvo a separarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_train = embendding[embendding[:,0] == 99.0,:] #train = 99\n",
    "vecs_test = embendding[embendding[:,0] == 100.0,:] #test = 100\n",
    "\n",
    "X_train = vecs_train[:,2:]\n",
    "y_train = vecs_train[:,1]\n",
    "X_test = vecs_test[:,2:]\n",
    "y_test = vecs_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embendding[:,2:]\n",
    "y = embendding[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size vecs_train (2662, 202)\n",
      "Size vecs_test (1142, 202)\n",
      "Size: \n",
      " * X_train: (2662, 200) \n",
      " * y_train: (2662,) \n",
      " * X_test: (1142, 200) \n",
      " * y_test: (1142,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size vecs_train\", vecs_train.shape)\n",
    "print(\"Size vecs_test\", vecs_test.shape)\n",
    "print(\"Size: \\n * X_train: %s \\n * y_train: %s \\n * X_test: %s \\n * y_test: %s\" % (X_train.shape, y_train.shape, X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (**SVM**) Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier = SVC(random_state=123, kernel=kernel, gamma=gamma, C=C)\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (**NB**) Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier = GaussianNB()\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (**RF**) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 1000\n",
    "min_samples_split = 5\n",
    "min_samples_leaf = 1\n",
    "max_features = 'sqrt'\n",
    "max_depth = 100\n",
    "bootstrap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = RandomForestClassifier(n_estimators=100,random_state=100,n_jobs=-1)\n",
    "classifier = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                    min_samples_split=min_samples_split,\n",
    "                                    min_samples_leaf=min_samples_leaf,\n",
    "                                    max_features=max_features,\n",
    "                                    max_depth=max_depth,\n",
    "                                    bootstrap=bootstrap,\n",
    "                                    random_state=100,n_jobs=-1)\n",
    "\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation solo con datos de entrenamiento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "skfold = StratifiedKFold(n_splits=10, random_state=100)\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold)\n",
    "print(\"Accuracy: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold, scoring='f1_macro')\n",
    "print(\"F1-score: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold, scoring='recall_macro')\n",
    "print(\"Recall: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X_train, y_train, cv=skfold, scoring='precision_macro')\n",
    "print(\"Precision: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation solo **todos los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.934806 (+/- 0.02)\n",
      "F1-score: 0.934691 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=10, random_state=100)\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X, y, cv=skfold)\n",
    "print(\"Accuracy: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = model_selection.cross_val_score(classifier, X, y, cv=skfold, scoring='f1_macro')\n",
    "print(\"F1-score: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "#scores = model_selection.cross_val_score(classifier, X, y, cv=skfold, scoring='recall_macro')\n",
    "#print(\"Recall: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "#scores = model_selection.cross_val_score(classifier, X, y, cv=skfold, scoring='precision_macro')\n",
    "#print(\"Precision: %0.6f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95024507, 0.92138839, 0.92353117, 0.94470583, 0.93142508,\n",
       "       0.93675626, 0.93937923, 0.92335246, 0.94997194, 0.92353117])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "metrics_svm = []\n",
    "metrics = {}\n",
    "metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "metrics['recall'] = recall_score(y_test, y_pred)\n",
    "metrics['precision'] = precision_score(y_test, y_pred)\n",
    "metrics['f1'] = f1_score(y_test, y_pred)\n",
    "metrics_svm.append(metrics)\n",
    "metrics_svm = pd.DataFrame(metrics_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy    recall  precision        f1\n",
      "0  0.936953  0.893238   0.976654  0.933086\n",
      "[[568  12]\n",
      " [ 60 502]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics_svm)\n",
    "print(cm_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
