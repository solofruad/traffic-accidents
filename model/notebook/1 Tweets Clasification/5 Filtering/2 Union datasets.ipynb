{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Union datasets **1_server_bogota**\n",
    "### By **Néstor Suat** in 2020\n",
    "\n",
    "**Descripción:** Como el dataset de **1_server_bogota** fué procesado por separado aquí se hace nuevamente la unión de las 4 partes.\n",
    "\n",
    "**Input:**\n",
    "* 4 parts\n",
    "\n",
    "**Output:**\n",
    "* Dataset consolidado **1_server_bogota**\n",
    "* Dataset consolidado Accidentes **1_server_bogota**\n",
    "* Dataset consolidado No Accidentes **1_server_bogota**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1_server_bogota.tsv -- 2,9 GB -- # 4’027.313 Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimiento para concatenar los 4 subdatasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filename = 'clf_1_server_bogota'\n",
    "#dir_ = '../../../data/database/output_ml/M1/'\n",
    "dir_ = '../../../data/database/output_ml/M2/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfp1 = pd.read_csv(dir_+filename+'_part1.tsv', delimiter = \"\\t\", quoting = 3 ) # Part1\n",
    "dfp2 = pd.read_csv(dir_+filename+'_part2.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "dfp3 = pd.read_csv(dir_+filename+'_part3.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "dfp4 = pd.read_csv(dir_+filename+'_part4.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "df = pd.concat([dfp1,dfp2,dfp3, dfp4])\n",
    "\n",
    "del dfp1['Unnamed: 0']\n",
    "del dfp2['Unnamed: 0']\n",
    "del dfp3['Unnamed: 0']\n",
    "del dfp4['Unnamed: 0']\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "print(df.shape,dfp1.shape, dfp2.shape, dfp3.shape, dfp4.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exporta la unión de los 4 subdatasets para más adelante utilizarlos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.to_csv(dir_+filename+\".tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimiento para concatenar los 4 subdatasets de Accidentes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filename = 'accident_1_server_bogota'\n",
    "#dir_ = '../../../data/database/output_ml/M1/'\n",
    "dir_ = '../../../data/database/output_ml/M2/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#df = pd.read_csv(dir_+filename, delimiter = \"\\t\", quoting = 3 )\n",
    "dfp1 = pd.read_csv(dir_+filename+'_part1.tsv', delimiter = \"\\t\", quoting = 3 ) # Part1\n",
    "dfp2 = pd.read_csv(dir_+filename+'_part2.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "dfp3 = pd.read_csv(dir_+filename+'_part3.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "dfp4 = pd.read_csv(dir_+filename+'_part4.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "df = pd.concat([dfp1,dfp2,dfp3, dfp4])\n",
    "\n",
    "del dfp1['Unnamed: 0']\n",
    "del dfp2['Unnamed: 0']\n",
    "del dfp3['Unnamed: 0']\n",
    "del dfp4['Unnamed: 0']\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "print(df.shape,dfp1.shape, dfp2.shape, dfp3.shape, dfp4.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exporta la unión de los 4 subdatasets de **ACCIDENTES** para más adelante utilizarlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv(dir_+filename+\".tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimiento para concatenar los 4 subdatasets de **NO Accidentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'no_accident_1_server_bogota'\n",
    "#dir_ = '../../../data/database/output_ml/M1/'\n",
    "dir_ = '../../../data/database/output_ml/M2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(dir_+filename, delimiter = \"\\t\", quoting = 3 )\n",
    "dfp1 = pd.read_csv(dir_+filename+'_part1.tsv', delimiter = \"\\t\", quoting = 3 ) # Part1\n",
    "dfp2 = pd.read_csv(dir_+filename+'_part2.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "dfp3 = pd.read_csv(dir_+filename+'_part3.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "dfp4 = pd.read_csv(dir_+filename+'_part4.tsv', delimiter = \"\\t\", quoting = 3 ) # Part2\n",
    "df = pd.concat([dfp1,dfp2,dfp3, dfp4])\n",
    "\n",
    "del dfp1['Unnamed: 0']\n",
    "del dfp2['Unnamed: 0']\n",
    "del dfp3['Unnamed: 0']\n",
    "del dfp4['Unnamed: 0']\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "print(df.shape,dfp1.shape, dfp2.shape, dfp3.shape, dfp4.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exporta la unión de los 4 subdatasets de **NO ACCIDENTES** para más adelante utilizarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dir_+filename+\".tsv\",sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
